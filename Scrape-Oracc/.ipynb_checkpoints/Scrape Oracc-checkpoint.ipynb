{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "The scraper output needs a field 'version' to make it compatible with ETCSL output. This field may be used for pseudo-composites such as [dcclt/Q000043](http://oracc.org/dcclt/Q000043) to indicate the designation of the tablet from which the text is taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ORACC Scraper\n",
    "\n",
    "Generalized scraper for [ORACC](html://oracc.org) files. The scraper needs an input file, that lists the P, Q, or X numbers to be scraped. It will create an output file for each of these P, Q, or X numbers with line numbers and lemmatized words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "Import the packages:\n",
    "- re Regular Expressions (for string manipulation)\n",
    "- BeautifulSoup (for parsing HTML pages)\n",
    "- tqdm for progress bar\n",
    "- ipywidgets for checkboxes and text input boxes\n",
    "- IPython.display to display widgets\n",
    "\n",
    "This scraper is written for Python3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#! pip install tqdm\n",
    "from __future__ import print_function\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from time import sleep\n",
    "from tqdm import *\n",
    "\n",
    "# Additional imports required for interactive outputter.\n",
    "# 1. ipywidgets to use checkboxes and text box widgets\n",
    "# 2. IPython.display to display these widgets\n",
    "from ipywidgets import Checkbox, interactive\n",
    "from IPython.display import display\n",
    "\n",
    "#this program should use python unit test\n",
    "PY3 = sys.version_info.major == 3\n",
    "\n",
    "if not PY3:\n",
    "    input = raw_input\n",
    "\n",
    "print(\"Running under Python version:\", sys.version_info[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Output Options\n",
    "- Select output variables to display by checking the box next to the data element. \n",
    "- To provide optional values to filter by for the selected elements, type the desired value in the text box. If the text box is left blank, the output will not be filtered on that field.\n",
    "- When multiple text boxes are filled with values, only output matching all the specifications are displayed.\n",
    "- If you want to filter in a way such that text matching any of the values listed should be outputted, type in a comma separated list for each element that is acceptable in the appropriate input field. For example, if you want to output text that is either Akkadian or Sumerian, in the 'lang' text box, type in akk,sux (or sux,akk - but no spaces in between options).\n",
    "- If you want to exclude certain values for an attribute (e.g. Akkadian for 'lang' or N for 'pos'), type in -akk or -N in the input box.\n",
    "- The default output is \"lang:citform[guide]pos\", so those 4 options are initially checked. The text fields are initially empty, so there are no restrictions (nothing is filtered out). \n",
    "- You can check and uncheck any of the options, as well as provide values to filter the output by.\n",
    "\n",
    "### Examples\n",
    "- Example 1: If we only want to display nouns, make sure pos is checked, and type in 'N' in the text field next to pos.\n",
    "- Example 2: If we only want display nouns, and the language if it is Sumerian, make sure lang and pos are checked, and type in 'sux' for lang and 'N' for pos. This will only output text that is both in Sumerian and a noun.\n",
    "- Example 3: If we want keep nouns, but only display 'lang', make sure lang is checked, and type in 'N' for pos. This will only output text with the language, and filter out text so that all outputs are nouns even though pos isn't displayed.\n",
    "- Special Edge Case: If you want to output all proper nouns, you can type QPN in the pos text box.\n",
    "\n",
    "### Summary:\n",
    "- Checkboxes are for choosing which options you want to display.\n",
    "- Input boxes are for filtering text whose values match the values in the boxes.\n",
    "- You can check boxes without filtering, and you can also type in values to filter by without checking the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Step 1: Create a list of all possible output options.\n",
    "l = [\"lang\", \"translit\", \"citform\", \"guide\", \"sense\", \"pos\", \"epos\", \"norm\", \"base\", \"morph\"]\n",
    "\n",
    "# Step 2: Create a checkbox widget for each element in the option list using a list comprehension. \n",
    "#         Set the description argument of checkbox equal to the variable \"a\", the element name.\n",
    "checks = [widgets.Checkbox(description=a) for a in l]\n",
    "\n",
    "# Step 3: Create a text box input widget for each element in the option list using a list comprehension. \n",
    "#         Set the description argument of checkbox equal to the empty string, since we don't want\n",
    "#         the option name to be repeated twice.\n",
    "inputs = [widgets.Text(description=\"\") for a in l]\n",
    "\n",
    "# Step 4: Sets the 'lang', 'citform', 'guide', and 'pos' checkboxes as checked from the start.\n",
    "for c in checks:\n",
    "    if c.description in ['lang', 'citform', 'guide', 'pos']:\n",
    "        c.value = True\n",
    "\n",
    "# Step 5: Combine the list of 10 checkboxes into one vertical column widget using VBox.\n",
    "checkboxes = widgets.VBox(checks)\n",
    "\n",
    "# Step 6: Combine the list of 10 input text boxes into one vertical column widget using VBox.\n",
    "inputboxes = widgets.VBox(inputs)\n",
    "\n",
    "# Step 7: Combine the two column widgets, checkboxes and inputboxes, to be side-by-side using HBox.\n",
    "combined_check_input = widgets.HBox([checkboxes, inputboxes])\n",
    "\n",
    "# Step 8: Display the combined widget.\n",
    "display(combined_check_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "textiderror = 'Not available:\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input File\n",
    "\n",
    "The input file should be located in a directory called /Input, which must be located in the directory in which this Python Notebook is found. The file should have a .txt extension and must be created with a flat text editor such as TextEdit, Notepad, or Emacs. The file contains a simple list of P, Q, or X numbers, preceded by the ORACC abbreviation where the file is edited. For instance:\n",
    "\n",
    "    rinap/rinap1/Q003421\n",
    "    dcclt/Q000039\n",
    "    cams/gkab/P348623\n",
    "\n",
    "Before running this scraper, use the same input file to download the text material (in html format) with the ORACC Downloader to the /Data directory.\n",
    "\n",
    "Run everything above this cell, select the output format options you wish to display with the checkboxes, and type in anything you want to include (e.g. V for verbs in the 'pos' field, akk for Akkadian in the 'lang' field), or exclude (put a \"-\" minus sign in front of what you want to exclude, e.g. -N in 'pos' excludes all nouns, -sux in 'lang' means no Sumerian) in the text boxes. Then run everything below this cell and type in the Input .txt file you want to scrape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputfile = input(\"Name of Input List: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format Output\n",
    "\n",
    "The function outputformat() defines what the output of the lemmatized forms will look like. This function may be adapted in various ways to produce different types of output. The function takes a dictionary as input with the following keys: \n",
    "\n",
    "- 1     lang: Language\n",
    "- 2     translit: Transliteration\n",
    "- 3     citform: Citation Form\n",
    "- 4     guide: Guide Word\n",
    "- 5     sense: Sense\n",
    "- 6     pos: Part of Speech\n",
    "- 7     epos: Effective Part of Speech\n",
    "- 8     norm: Normalization\n",
    "- 9     base: Base (Sumerian only)\n",
    "- 10    morph: Morphology (Sumerian only)\n",
    "\n",
    "In the standard format the output will look like: sux:lugal[king]N. One may adapt the output, for instance, by omitting the element lang (lugal[king]N) or to select for certain parts of speech, or for certain language codes. For instance:\n",
    "```python\n",
    "    if output['pos'] == 'N':\n",
    "        output_formatted = output['citform'] + \"\\t\" + output['guide']\n",
    "```\n",
    "This will create output in the form lugal   king (lugal and king seperated by TAB), selecting only Nouns (excluding Proper Nouns).\n",
    "\n",
    "```python\n",
    "    if output['lang'] == 'sux-x-emesal':\n",
    "        output_formatted = output['citform'] + \"[\" + output['guide'] + \"]\" + output['pos']\n",
    "```\n",
    "This will create output in the form umun[lord]N, selecting only Emesal words.\n",
    "In order to select both Sumerian (sux) and Emesal (sux-x-emesal) forms one could use:\n",
    "```python\n",
    "    if output['lang'][0:3] == 'sux':\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This code may be used (instead of the next cell) to only return proper nouns in the format CF[GW]POS:\n",
    "`def outputformat(output):\n",
    "    #output_formatted = ''\n",
    "    QPN = ('AN', 'CN', 'DN', 'EN', 'FN', 'GN', 'LN', 'MN', 'ON', 'PN', 'QN', 'RN', 'SN', 'TN', 'WN', 'YN')\n",
    "    if output['pos'] in QPN:\n",
    "        output_formatted = output['citform'] + \"[\" + output['guide'] + \"]\" + output['pos']\n",
    "    else:\n",
    "        return None\n",
    "    return output_formatted`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of proper nouns for the special QPN edge case.\n",
    "QPN = ('AN', 'CN', 'DN', 'EN', 'FN', 'GN', 'LN', 'MN', 'ON', 'PN', 'QN', 'RN', 'SN', 'TN', 'WN', 'YN')\n",
    "\n",
    "# Step 1: Use a list comprehension to store all checkboxes that are true. \"for c in checks\" iterates\n",
    "#         through all the checkboxes, and \"if c.value\" only keeps the ones that are marked true.\n",
    "#         We store the checkboxes marked true in a tuple, (option name, corresponding value in the input box).\n",
    "#         Option name is just the description argument in checkbox. We get the value of the input box\n",
    "#         by finding the equivalent index of c (checks.index(c)) in the inputs list, and then getting the value\n",
    "#         of this input box element. This relies on the fact that the index of the checkbox corresponds \n",
    "#         to the index of the input box. For example, index 0 for the checkbox list is 'lang', and\n",
    "#         index 0 for the inputs list contains the value of 'lang' if we want to filter it.\n",
    "\n",
    "options_selected = [(c.description, inputs[checks.index(c)].value) for c in checks if c.value]\n",
    "\n",
    "# Step 2: Use a list comprehension to store all restrictions, i.e. text fields that are filled. \n",
    "#         \"for i in inputs\" iterates through all the input boxes, and \"i.value != '' \" only keeps \n",
    "#         the ones that are filled with some text. We store the restrictions in a tuple, \n",
    "#         (option name in corresponding checkbox, value in the input box). Option name is the description \n",
    "#         argument of the corresponding checkbox element. We can get the option name using the \n",
    "#         same corresponding index strategy as in step 1. i.value is the value in the input box.\n",
    "#         i.value != '' and i.value[0] != \"-\" tells us which values should be the only ones included.\n",
    "#         i.value != '' and i.value[0] == \"-\" means the value starts with a negative, so we exclude it.\n",
    "\n",
    "keep = [(checks[inputs.index(i)].description, i.value) for i in inputs if i.value != '' and i.value[0] != \"-\"]\n",
    "ban = [(checks[inputs.index(i)].description, i.value) for i in inputs if i.value != '' and i.value[0] == \"-\"]\n",
    "\n",
    "# Step 3: Write a function that takes in the output and a list of restrictions.\n",
    "#         Returns True if the output meets every restriction.\n",
    "#         Returns False if it fails to meet at least one restriction.\n",
    "\n",
    "def conforms(output, keep, ban):\n",
    "    for k in keep:\n",
    "        # Special edge case for QPN proper nouns.\n",
    "        # The continue statement stops the current iteration, and\n",
    "        # forces the for loop to move on to the next restriction.\n",
    "        if k[0] == 'pos' and k[1] == 'QPN' and output['pos'] in QPN:\n",
    "            continue\n",
    "        \n",
    "        # If the output's value (output[r[0]]) for an element, r[0], \n",
    "        # is not in the list of permitted values (r[1]) inputted in the text box \n",
    "        # for that element, immediately return False.\n",
    "        if output[k[0]] not in k[1].split(','):\n",
    "            return False\n",
    "        \n",
    "    for b in ban:\n",
    "        # Special edge case for QPN proper nouns.\n",
    "        # If text is -QPN, exclude all QPN words.\n",
    "        if b[0] == 'pos' and b[1][1:]  == 'QPN' and output['pos'] in QPN:\n",
    "            return False\n",
    "        \n",
    "        # If the output's value (output[r[0]]) for an element, r[0], \n",
    "        # is on the excluded list, immediately return False.\n",
    "        if \"-\" + output[b[0]] in b[1].split(','):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "# Step 4: Given the output, the data element, and the list of all options checked, add the \n",
    "#         appropriate separators before and after the output's value for this data element.\n",
    "#         Return the string of the output's value for this data element with punctuation added.\n",
    "\n",
    "def addSeparators(output, field, all_options):\n",
    "    # This if statement deals with the case when 'morph' and/or 'base' are checked\n",
    "    # and the output is not Sumerian. Only Sumerian and Emesal words have morph and base elements. \n",
    "    # If the language of the text does not start with 'sux' and we are adding\n",
    "    # separators for 'base' or 'morph', this function returns the empty string\n",
    "    # to avoid a KeyError.\n",
    "    \n",
    "    if output['lang'][0:2] != 'sux' and (field == 'base' or field == 'morph'):\n",
    "        return \"\"\n",
    "    \n",
    "    # The text variable holds the value of the element in the text.\n",
    "    text = output[field]\n",
    "    \n",
    "    # Depending on which data element we are working with, we have to prepend\n",
    "    # or append certain punctuation marks to complete the ORACC signature.\n",
    "    # If the data element we are considering does not need any additional\n",
    "    # punctuation, we simply return the text variable at the end.\n",
    "    \n",
    "    if field == 'lang':\n",
    "        return text + \":\"\n",
    "    if field == 'translit':\n",
    "        return text + \"=\"\n",
    "    \n",
    "    # For the guide word and sense case, if only one is checked, surround it with [].\n",
    "    # If both are checked, put the \"[\" before the guide word, the \"//\" before the\n",
    "    # sense, and \"]\" after the sense.\n",
    "    \n",
    "    if field == 'guide':\n",
    "        if 'sense' not in [a[0] for a in all_options]:\n",
    "            return \"[\" + text + \"]\"\n",
    "        return \"[\" + text\n",
    "    if field == 'sense':\n",
    "        if 'guide' not in [a[0] for a in all_options]:\n",
    "            return \"[\" + text + \"]\"\n",
    "        return \"//\" + text + \"]\"\n",
    "    \n",
    "    if field == 'epos':\n",
    "        return \"'\" + text\n",
    "    if field == 'norm':\n",
    "        return \"$\" + text\n",
    "    if field == 'base':\n",
    "        return \"/\" + text\n",
    "    if field == 'morph':\n",
    "        return \"#\" + text\n",
    "    return text\n",
    "    \n",
    "# Step 5: Write the function that builds the actual output\n",
    "#         given a dictionary of the values for the data elements\n",
    "#         in the text.\n",
    "\n",
    "def outputformat(output):\n",
    "    # Only output text that meets the restrictions.\n",
    "    if conforms(output, keep, ban):\n",
    "        \n",
    "        # Start with an empty string.\n",
    "        output_formatted = ''\n",
    "        \n",
    "        # For all data elements checked\n",
    "        for options in options_selected:\n",
    "            # Concatenate the value of each data element checked \n",
    "            # with its punctuation to the existing formatted output.\n",
    "            # options[0] gives the name of the data element.\n",
    "            \n",
    "            output_formatted += addSeparators(output, options[0], options_selected)\n",
    "            \n",
    "        return output_formatted\n",
    "    \n",
    "    # Texts that do not meet the restrictions return None.\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse an ORACC lemma\n",
    "\n",
    "The function `parselemma()` parses a so-called ORACC 'signature.' It is called by the `getline()` function where these signatures are extracted from the html files. A signature, as extracted by the `getline()` function, looks as follows:\n",
    "\n",
    "> javascript:pop1sig('dcclt','','@dcclt%sux:am-si=amsi[elephant//elephant]N´N$amsi/am-si#~').\n",
    "\n",
    "Akkadian signatures look slightly different, lacking the last two elements (after the /). The `parselemma()` function removes all the superfluous elements and breaks the string up into its parts. It returns a dictionary that lists all of these parts. The function `getline()` forwards this dictionary to the function `formatoutput()`, which uses its keys and values to build a usable data structure and/or to filter the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parselemma(signature):\n",
    "    output = {}\n",
    "    signature = signature.replace(' ', '-')\n",
    "    signature = signature.replace(',', ';') #remove spaces and commas from GuideWord and Sense\n",
    "    oracc_words = re.sub(\"'\\)$\", \"\", signature) #remove ') from the end of the signature\n",
    "    oracc_words = re.sub('^[^%]*%', '', oracc_words) #remove everything before the first % in the signature\n",
    "    \n",
    "    sep_char = [\":\", \"=\", \"$\", \"#\", \"[\", \"]\", \"//\"] # these are the character sequences that separate\n",
    "                                                    # the various elements of the signature\n",
    "    for eachchar in sep_char:\n",
    "        oracc_words = oracc_words.replace(eachchar, \" \", 1) # ':' may appear in guideword/sense, so replace only once\n",
    "    \n",
    "    oracc_words_l = oracc_words.split() #split signature into a list\n",
    "    output['lang'] = oracc_words_l[0]\n",
    "    output['translit'] = oracc_words_l[1]\n",
    "    output['citform'] = oracc_words_l[2]\n",
    "    output['guide'] = oracc_words_l[3]\n",
    "    output['sense'] = oracc_words_l[4]\n",
    "\n",
    "    oracc_words_l[5] = oracc_words_l[5].replace(\"´\", \" \") # this separates pos from epos\n",
    "    oracc_words_l[5] = oracc_words_l[5].split() #split into sub-list\n",
    "    output['pos'] = oracc_words_l[5][0]\n",
    "    output['epos'] = oracc_words_l[5][1]\n",
    "    \n",
    "    if output['lang'][0:2] == 'sux': # Sumerian or Emesal signature\n",
    "        oracc_words_l[6] = oracc_words_l[6].replace(\"/\", \" \") # this separates norm from base in sux\n",
    "        oracc_words_l[6] = oracc_words_l[6].split() #split into sub-list\n",
    "        output['norm'] = oracc_words_l[6][0]\n",
    "        output['base'] = oracc_words_l[6][1]\n",
    "        output['morph'] = oracc_words_l[7]\n",
    "    \n",
    "    else:\n",
    "        output['norm'] = oracc_words_l[6]\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compound Orthographic Forms\n",
    "\n",
    "Compound Orthographic Forms are combinations of two or more words that are written with a single graphemic complex. Examples are *im-ma-ti* for *ina mati* (when?) or {lu₂}EN.NAM for *bēl pīhati* (governor). In ORACC HTML, the words in a COF are combined in a single signature, separated by '&&':\n",
    "\n",
    "> javascript:pop1sig('saao/saa10','','@saao/saa10%akk-x-neoass:im-ma-ti=ina[in//in]PRP´PRP\\$ina&&@saao/saa10%akk-x-neoass:=mati[when?//when?]QP´QP\\$mati')\n",
    "\n",
    "The function `cof()` is called, when necessary, by `getline()`. It splits the signature at the '&&' separator and returns a list of signatures. The transliteration (in this case *im-ma-ti*), which is included only in the first signature, is isolated and assigned to the variable `translit`. This transliteration is inserted in the remaining signatures at the proper place.\n",
    "\n",
    "Occasionally, in some COF signatures, the second and further words do not have their own normalization (introduced by $) - this is, presumably, an irregularity in ORACC. If this is the case, normalization is supplied by assuming that it is equal to the citation form in the function `supplynorm()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cof(signature):\n",
    "    signature = signature.replace(\"javascript:pop1sig('\", \"\")\n",
    "    signature = signature.replace(\"')\", \"\")\n",
    "    translit = re.search(':(.*?)=', signature).group(1) #TODO replace the expression with positive look back\n",
    "                                                        # and positive look ahead expression\n",
    "    cofsignatures = signature.split('&&@')\n",
    "    cofsignatures = [cofsignature.replace(':=', ':' + translit + '=') for cofsignature in cofsignatures]\n",
    "\n",
    "    def supplynorm(cofsignature):\n",
    "        if not '$' in cofsignature:\n",
    "            citform = re.search('=(.*?)\\[', cofsignature).group(1)\n",
    "            cofsignature = cofsignature + '$' + citform\n",
    "        return cofsignature\n",
    "    \n",
    "    cofsignatures = [supplynorm(cofsignature) for cofsignature in cofsignatures]\n",
    "        \n",
    "    return cofsignatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process a Line\n",
    "\n",
    "The function `getline()` receives a line with metadata from the function `scrape()`. It returns a single variable (`line`) that contains the lines metadata and the formatted lemmata in a single string. \n",
    "\n",
    "The function needs two arguments. The first, `line_label`, includes all the metadata of the line: `id_text`, `text_name`, and `l_no` in a single string (separated by commas). The second argument, `line`, is a `BeautifulSoup` object that holds the HTML representation of a single line.\n",
    "\n",
    "Each line contains a series of words, represented as `signatures` in ORACC HTML. The function collects the signatures in the list `lemmas` and iterates over these. If a signature represents a Compound Orthographic Form (a combination of multiple lemmas, separated by '&&') it is sent to the function `cof()` in order to split the signature in its component forms.\n",
    "\n",
    "Each signature is sent to `parselemma()`, where it is analyzed. The function `parselemma()` returns a dictionary (`output`) that contains all the elements of the signature (transliteration, citation form, guide word, etc.). This dictionary is sent to the function `outputformat()` which returns a string, combining elements of the signature in the desired format (the default is language:citform[guide]pos, as in sux:lugal[king]N). This string is added to the list `wordsinline`. Finally, once all lemmas (signatures) have been processed, the function builds a single string out of the `line_label` (metadata) and the formatted lemmas in `wordsinline`. This string is returned in the variable `line`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getline(line_label, line):\n",
    "    wordsinline = [] #initialize list for the words in this line\n",
    "    lemmas = line.findAll('a', {'class':'cbd'}, href=True)\n",
    "    for eachlemma in lemmas:\n",
    "        signature = eachlemma['href']\n",
    "        if '&&@' in signature:  #Compound Orthographic Form, which results in multiple lemmas\n",
    "            cofsignatures = cof(signature)\n",
    "            for cofsignature in cofsignatures:\n",
    "                output = parselemma(cofsignature)\n",
    "                output_formatted = outputformat(output)\n",
    "                if not output_formatted == None:\n",
    "                    wordsinline.append(output_formatted)\n",
    "        else:\n",
    "            output = parselemma(signature)\n",
    "            output_formatted = outputformat(output)\n",
    "            if not output_formatted == None:\n",
    "                wordsinline.append(output_formatted)\n",
    "    line = line_label + ' '.join(wordsinline)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape a Single Text\n",
    "\n",
    "The function `scrape()` takes a single text file and uses the `BeautifulSoup` package to analyze the HTML and return the data in a csv (Comma Separated Values) format. The function is called by the main process.\n",
    "\n",
    "The function `scrape()` first identifies the name (or designation) of the text - if it cannot find the name, the text is not further processed and an error message is returned.\n",
    "\n",
    "The function then identifies a line and sends this line to the function `getline()` for further processing. The line number is a string that belongs to the attribute `class = 'xlabel'`. Text name, text id and line number are combined into a single string as `line_label` - which is sent to `getline()` as its first argument (the second is the line itself).\n",
    "\n",
    "If there is no `class = 'xlabel'` attribute, this means that the line belongs with the previous line as a single unit. This happens in interlinear bilinguals and, occasionally, in the representation of explanatory glosses (see, e.g. SAA 10, 044). In such cases the variable `line` from the previous iteration (which is a single string, concatenating `line_label` and the formatted lemmas) is sent, in its entirety, as the first argument to `getline()` so that the new lemma or lemmas will be added to the end of it.\n",
    "\n",
    "Finally all lines are assembled in the variable `csvformat`, which is returned to the main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def scrape(text_id):\n",
    "    print('Parsing ' + text_id)\n",
    "    line = ''\n",
    "    csvformat ='id_text,text_name,version,l_no,text\\n' #initialize output variable\n",
    "    with open('HTML/' + text_id.replace('/', '_') + '.html', encoding='utf8') as f:\n",
    "        raw_html = f.read()\n",
    "    soup = BeautifulSoup(raw_html, \"html.parser\")\n",
    "    name = soup.find('h1', {'class':'p3h2'}).string\n",
    "    #if there is no text name, there are errors in atf and page was not built correctly\n",
    "    if name == None:\n",
    "        print(eachtextid + \" is not built correctly.\")\n",
    "    else:\n",
    "        #if name includes comma, replace comma with nothing\n",
    "        name = name.replace(',','')\n",
    "        print(eachtextid + \":\" + name)\n",
    "        #all line HTML tags and also tags of the form\n",
    "        #<div dc:title=\"...\"> which contains the versions\n",
    "        #as their text. We will find all lines containing\n",
    "        #signatures plus the version headers if applicable\n",
    "        lines = soup.findAll(lambda tag: (tag.name == 'tr' and 'class' in tag.attrs and tag.attrs['class'][0] == 'l') \n",
    "                                    or (tag.name == 'div' and 'dc:title' in tag.attrs))\n",
    "        version = '' # set default version to empty string at the very beginning\n",
    "        for index, eachline in enumerate(lines):\n",
    "            #all versions are included as text inside <a target=\"_blank\"> tags, \n",
    "            #so we look for these tags for each line\n",
    "            #if text never has any versions, BeautifulSoup will never\n",
    "            #find these 'a' tags so version is the default value \"\"\n",
    "            subtitle = eachline.find('a', {'target': '_blank'})\n",
    "            #check if the line contains this type of tag\n",
    "            if subtitle:\n",
    "                version = subtitle.string.replace(',', '') # assign the tag's text to the version variable\n",
    "            if eachline.find('a', {'class':'cbd'}, href=True) == None: # if the line has no words\n",
    "                continue                                               # go to next line\n",
    "            if eachline.find('span', {'class': 'xlabel'}) != None and eachline.find('span', {'class': 'xlabel'}).string != None:\n",
    "                l_no = eachline.find('span', {'class': 'xlabel'}).string.replace(',', ';')\n",
    "                line_label = text_id + ',' + name + ',' + version + ',' + l_no + ','\n",
    "                line = getline(line_label, eachline)\n",
    "                try:\n",
    "                    nextline = lines[index + 1]\n",
    "                    if nextline.find('span', {'class': 'xlabel'}) == None: #if next line has no line number\n",
    "                        if nextline.find('a', {'class':'cbd'}, href=True) == None: #ignore if there are no lemmatized words\n",
    "                            continue                                               # in next line\n",
    "                        else:\n",
    "                            line_label = line + ' '                         # otherwise join output with previous line\n",
    "                            line = getline(line_label, nextline)\n",
    "                except:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "            csvformat = csvformat + line + '\\n'\n",
    "    return csvformat\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Process\n",
    "\n",
    "The main process opens the list of text IDs (in the directory `Input`) to be processed and iterates over that list. The process calls the function `scrape()` which, in turn, calls the other functions defined above.\n",
    "\n",
    "The function creates a separate file for each of the scraped documents in the directory Output. A list of texts that could not be scraped is saved in the directory Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('Input/' + inputfile, mode = 'r', encoding='utf8') as f:\n",
    "    textlist = f.read().splitlines()\n",
    "for eachtextid in tqdm(textlist):\n",
    "    sleep(0.01)\n",
    "    eachtextid = eachtextid.rstrip()\n",
    "    file = 'HTML/' + eachtextid.replace('/', '_') + '.html'\n",
    "    try:\n",
    "        csvformat = scrape(eachtextid)\n",
    "        outputfile = 'Output/' + eachtextid.replace('/', '_') + '.txt'\n",
    "        print(\"Saving \" + outputfile + '\\n')\n",
    "    \n",
    "        if not os.path.exists('Output'):\n",
    "            os.mkdir('Output')\n",
    "        \n",
    "        with open(outputfile, mode = 'w', encoding='utf8') as writeFile:\n",
    "            writeFile.write(csvformat)  \n",
    "\n",
    "    except IOError:\n",
    "        print(file + ' not available')\n",
    "        textiderror = textiderror + eachtextid + '\\n'\n",
    "\n",
    "#Create error log\n",
    "if not os.path.exists('Error'):\n",
    "    os.mkdir('Error')\n",
    "with open('Error/oraccerror.txt', mode='w', encoding='utf8') as writeFile:\n",
    "    writeFile.write(textiderror)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "e0dcc2fce5e14657b4e38949b557f0ac": {
     "views": [
      {
       "cell_index": 5
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
