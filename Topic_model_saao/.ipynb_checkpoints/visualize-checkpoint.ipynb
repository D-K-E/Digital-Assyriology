{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Model of the State Archives of Assyria Letters\n",
    "\n",
    "This is a work-in-progress Notebook. The number of topics is set with the ntopics variable. There are almost 2500 letters, most of them brief or very brief. The topic model produced from the entire corpus (with 15 or 25 topics) is hard to interpret. One reason may be that the texts are too short. A brief or broken letter with just a few words that happen to be important in a certain topic may come out as one of the most important documents in that topic (because a high percentage of that letter resides in the topic). One solution may be to group (aggregate) letters by metadata, in the file SAAO.csv. One could group the letters by Chapter number (this referes to chapters in the original book publications - assuming that those chapters group texts that are related in a meaningful way)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pyLDAvis\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.utils.fixes import sp_version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and Versions\n",
    "The following code checks for the versions of the packages pyLDAvis, scikit-learn, and pandas and will install updates when necessary. pyLDAvis 2.0 is incompatible with Pandas 0.19. The MDS and tSNE computations necessary for plotting the distribution of documents in the topic model need scikit-learn 0.18. This notebook was written for Python 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyLDAvis version 2.0.0. You need to update to pyLDAvis 2.1.0 or later.\n",
      "do you want to proceed? y/n y\n",
      "Requirement already up-to-date: pyLDAvis in c:\\users\\jason kha\\anaconda3\\lib\\site-packages\n",
      "Requirement already up-to-date: jinja2>=2.7.2 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: pytest in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: future in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: scipy>=0.18.0 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: numpy>=1.9.2 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: pandas>=0.17.0 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: joblib>=0.8.4 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: funcy in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: numexpr in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: wheel>=0.23.0 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pyLDAvis)\n",
      "Requirement already up-to-date: MarkupSafe in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from jinja2>=2.7.2->pyLDAvis)\n",
      "Requirement already up-to-date: py>=1.4.29 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis)\n",
      "Requirement already up-to-date: colorama; sys_platform == \"win32\" in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pytest->pyLDAvis)\n",
      "Requirement already up-to-date: python-dateutil>=2 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis)\n",
      "Requirement already up-to-date: pytz>=2011k in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from pandas>=0.17.0->pyLDAvis)\n",
      "Requirement already up-to-date: six>=1.5 in c:\\users\\jason kha\\anaconda3\\lib\\site-packages (from python-dateutil>=2->pandas>=0.17.0->pyLDAvis)\n"
     ]
    }
   ],
   "source": [
    "if sp_version < (0, 18):\n",
    "    print('scikit-learn version ' + str(sp_version) + '. You need to update to scikit-learn 0.18 or later.')\n",
    "    y_n = input('do you want to proceed? y/n ')\n",
    "    if y_n == 'y':\n",
    "        !pip install -U scikit-learn\n",
    "\n",
    "pdv = pd.__version__.split('.')\n",
    "if int(pdv[1]) < 19:\n",
    "    print('pandas version ' + pd.__version__ + '. You need to update to pandas 0.19 or later.')\n",
    "    y_n = input('do you want to proceed? y/n ')\n",
    "    if y_n == 'y':\n",
    "        !pip install -U pandas\n",
    "\n",
    "pyLDAvisv = pyLDAvis.__version__.split('.')\n",
    "if int(pyLDAvisv[0]) < 2 or int(pyLDAvisv[1]) <  1:\n",
    "    print('pyLDAvis version ' + pyLDAvis.__version__ + '. You need to update to pyLDAvis 2.1.0 or later.')\n",
    "    y_n = input('do you want to proceed? y/n ')\n",
    "    if y_n == 'y':\n",
    "        !pip install -U pyLDAvis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in Data\n",
    "First read the directory with the State Archives of Assyria letters. These files contain lemmatization in ORACC. The texts list lemmatizations per line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>l_no</th>\n",
       "      <th>text</th>\n",
       "      <th>text_name</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>o 1</td>\n",
       "      <td>awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>o 2</td>\n",
       "      <td>šulmu[completeness]N ana[to]PRP libbu[interior...</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>o 3</td>\n",
       "      <td>ša[that]REL šapāru[send]V mā[saying]PRP māru[s...</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>o 4</td>\n",
       "      <td>Muskaya[Phrygian]EN ina[in]PRP muhhu[skull]N a...</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>o 5</td>\n",
       "      <td>Quwaya[from-Quwe]EN ša[that]REL Urik[1]PN ana[...</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id_text l_no                                               text  \\\n",
       "0  saao/saa01/P224485  o 1  awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...   \n",
       "1  saao/saa01/P224485  o 2  šulmu[completeness]N ana[to]PRP libbu[interior...   \n",
       "2  saao/saa01/P224485  o 3  ša[that]REL šapāru[send]V mā[saying]PRP māru[s...   \n",
       "3  saao/saa01/P224485  o 4  Muskaya[Phrygian]EN ina[in]PRP muhhu[skull]N a...   \n",
       "4  saao/saa01/P224485  o 5  Quwaya[from-Quwe]EN ša[that]REL Urik[1]PN ana[...   \n",
       "\n",
       "                                           text_name version  \n",
       "0  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...     NaN  \n",
       "1  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...     NaN  \n",
       "2  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...     NaN  \n",
       "3  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...     NaN  \n",
       "4  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...     NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path =r'../Scrape-Oracc/Output/' # use your path\n",
    "allFiles = glob.glob(path + \"/saao\" + \"*.txt\")\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "saao_data = pd.concat(list_)\n",
    "saao_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collapse lines to one row per document\n",
    "In order to transform this DataFrame into a proper input for topic modeling we need to discard the column `l_no` and concatenate all the text that belongs to one letter in a single row. Some lines have no content in the `text` column - these lines need to be dropped.\n",
    "\n",
    "First select the relevant columns and drop the rows that have no text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_text</th>\n",
       "      <th>text_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>šulmu[completeness]N ana[to]PRP libbu[interior...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>ša[that]REL šapāru[send]V mā[saying]PRP māru[s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>Muskaya[Phrygian]EN ina[in]PRP muhhu[skull]N a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saao/saa01/P224485</td>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>Quwaya[from-Quwe]EN ša[that]REL Urik[1]PN ana[...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id_text                                          text_name  \\\n",
       "0  saao/saa01/P224485  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...   \n",
       "1  saao/saa01/P224485  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...   \n",
       "2  saao/saa01/P224485  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...   \n",
       "3  saao/saa01/P224485  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...   \n",
       "4  saao/saa01/P224485  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...   \n",
       "\n",
       "                                                text  \n",
       "0  awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...  \n",
       "1  šulmu[completeness]N ana[to]PRP libbu[interior...  \n",
       "2  ša[that]REL šapāru[send]V mā[saying]PRP māru[s...  \n",
       "3  Muskaya[Phrygian]EN ina[in]PRP muhhu[skull]N a...  \n",
       "4  Quwaya[from-Quwe]EN ša[that]REL Urik[1]PN ana[...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saao_data = saao_data[['id_text', 'text_name', 'text']]\n",
    "saao_data = saao_data.dropna()\n",
    "saao_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the rows by `id_text` and apply the `join` function to the `text` column. Transform the aggregated data into a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P224485</th>\n",
       "      <td>awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313416</th>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313417</th>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313425</th>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313427</th>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text\n",
       "id_text                                                              \n",
       "saao/saa01/P224485  awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...\n",
       "saao/saa01/P313416  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...\n",
       "saao/saa01/P313417  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...\n",
       "saao/saa01/P313425  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...\n",
       "saao/saa01/P313427  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saao_byletter = saao_data['text'].groupby(saao_data['id_text']).apply(' '.join)\n",
    "saao_byletter_df = pd.DataFrame(saao_byletter)\n",
    "saao_byletter_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Create a DataFrame of `id_text` and `text_name` equivalencies, with `id_text` set as index (row names). Then merge this DataFrame with the the `saao_bytext_df` using the indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P224485</th>\n",
       "      <td>SAA 01 001. Midas Of Phrygia Seeks Detente (NL...</td>\n",
       "      <td>awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313416</th>\n",
       "      <td>SAA 01 158. Gold and Silver Objects Sent to th...</td>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313417</th>\n",
       "      <td>SAA 01 233. More Land to Bel-duri (CT 53 002)</td>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313425</th>\n",
       "      <td>SAA 01 179. No Iron to the Arabs! (CT 53 010)</td>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saao/saa01/P313427</th>\n",
       "      <td>SAA 01 152. The Affair of Gidgidanu and His Br...</td>\n",
       "      <td>ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            text_name  \\\n",
       "id_text                                                                 \n",
       "saao/saa01/P224485  SAA 01 001. Midas Of Phrygia Seeks Detente (NL...   \n",
       "saao/saa01/P313416  SAA 01 158. Gold and Silver Objects Sent to th...   \n",
       "saao/saa01/P313417      SAA 01 233. More Land to Bel-duri (CT 53 002)   \n",
       "saao/saa01/P313425      SAA 01 179. No Iron to the Arabs! (CT 53 010)   \n",
       "saao/saa01/P313427  SAA 01 152. The Affair of Gidgidanu and His Br...   \n",
       "\n",
       "                                                                 text  \n",
       "id_text                                                                \n",
       "saao/saa01/P224485  awātu[word]N šarru[king]N ana[to]PRP Aššur-šar...  \n",
       "saao/saa01/P313416  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...  \n",
       "saao/saa01/P313417  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...  \n",
       "saao/saa01/P313425  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...  \n",
       "saao/saa01/P313427  ana[to]PRP šarru[king]N bēlu[lord]N ardu[slave...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saao_id_names = saao_data[['id_text', 'text_name']].drop_duplicates().set_index('id_text')\n",
    "saao_data_df = pd.merge(saao_id_names, saao_byletter_df, right_index=True, left_index=True)\n",
    "saao_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import gensim\n",
    "    from gensim import corpora, models, utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test corpus: first 100 texts\n",
    "[For test purposes only the first 100 documents are admitted.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#saao_data_df = saao_data_df[:100]\n",
    "documents = saao_data_df['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize and POS-filter\n",
    "Tokenization is done by splitting on white space. The variable `posfilter` holds the last two characters of lemmatized words with allowed Part of Speech tags. If, for instance, you wish to select Verbs, Adjectives, and Nouns (in Akkadian), posfilter will be `[']n', 'aj', ']v']`. Note that one-character pos-tags need the right bracket!\n",
    "The POS labels are:\n",
    "* \"n\", #Nouns\n",
    "* \"v\", #Verbs\n",
    "* \"aj\", #Adjectives\n",
    "* \"av\", #Adverbs\n",
    "* \"an\", #Agricultural Name\n",
    "* \"cn\", #Celestial Name\n",
    "* \"dn\", #Divine Name\n",
    "* \"en\", #Ethnicity Name\n",
    "* \"fn\", #Field Name\n",
    "* \"gn\", #Geographical Name (lands, etc.)\n",
    "* \"ln\", #Lineage Name (ancestral clan)\n",
    "* \"mn\", #Month Name\n",
    "* \"on\", #Object Name\n",
    "* \"pn\", #Personal Name\n",
    "* \"qn\", #Quarter (of a city) Name\n",
    "* \"rn\", #Royal Name\n",
    "* \"sn\", #Settlement Name\n",
    "* \"tn\", #Temple Name\n",
    "* \"wn\", #Watercourse Name\n",
    "* \"yn\", #Year Name\n",
    "* \"nu\", #Numeral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posfilter = [']n', ']v', 'en']\n",
    "#texts = [[word for word in document.lower().split()] for document in documents]\n",
    "texts = [[word for word in document.lower().split() if word[-2:] in posfilter] for document in documents]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words\n",
    "\n",
    "Stop words are very frequent words that are not able to distinguish between topics. This includes, for instance, prepositions - but those have already been filtered out by the POS filter. The following nouns and verbs are too frequent to contribute to the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stoplist = [\n",
    "'šarru[king]n',\n",
    "'bēlu[lord]n',\n",
    "'libbu[interior]n',\n",
    "'muhhu[skull]n',\n",
    "'ardu[slave]n',\n",
    "'šulmu[completeness]n',\n",
    "'šapāru[send]v',\n",
    "'alāku[go]v',\n",
    "'qabû[say]v',\n",
    "'pānu[front]n',\n",
    "'māru[son]n',\n",
    "'bītu[house]n',\n",
    "'epēšu[do]v',\n",
    "'wabālu[bring]v',\n",
    "'šakānu[put]v',\n",
    "'amāru[see]v',\n",
    "'bašû[exist]v',\n",
    "'našû[lift]v',\n",
    "'izuzzu[stand]v',\n",
    "'ūmu[day]n',\n",
    "'ṭābu[good]aj',\n",
    "'mādu[many]aj',\n",
    "'nadānu[give]v',\n",
    "'tadānu[give]v',\n",
    "'ṣehru[small]aj',\n",
    "'mimmû[all]n',\n",
    "'gimru[totality]n',\n",
    "'gabbu[totality]n',\n",
    "'šâlu[ask]v',\n",
    "'šemû[hear]v',\n",
    "'ūmu[day]n',\n",
    "'awātu[word]n',\n",
    "'erēbu[enter]v']\n",
    "texts = [[word for word in text if word not in stoplist] for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary\n",
    "create the gensim Dictionary and filter for words that are too common or too rare (no_above may be set too low here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=1, no_above=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "ntopics = 10\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(corpus, num_topics=ntopics, id2word = dictionary, passes=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the top words and their probabilities in all topics. Note: the topic numbers here are not the ones used below in the visualizations! (The topics are the same, but not their numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('sisû[horse]n', 0.10083936001433579),\n",
       "   ('wadû[know]v', 0.017973252318865277),\n",
       "   ('urû[team]n', 0.017328173611228712),\n",
       "   ('manû[unit]n', 0.013002251147283634),\n",
       "   ('kūdanu[mule]n', 0.012501699862930442),\n",
       "   ('karābu[pray]v', 0.012471666007042434),\n",
       "   ('ēkallu[palace]n', 0.012236440567826353),\n",
       "   ('pēthallu[riding-horse]n', 0.011682692542214455),\n",
       "   ('biltu[load]n', 0.011308738852951377),\n",
       "   ('nišu[people]n', 0.011230677378481976)]),\n",
       " (1,\n",
       "  [('alpu[ox]n', 0.049445477475372077),\n",
       "   ('nāru[river]n', 0.034203704946254847),\n",
       "   ('immeru[sheep]n', 0.029858148189514554),\n",
       "   ('gušūru[tree-trunk]n', 0.027382004757944257),\n",
       "   ('matāhu[lift]v', 0.025137023660794827),\n",
       "   ('ēkallu[palace]n', 0.024670101607569859),\n",
       "   ('qātu[hand]n', 0.023886636055080353),\n",
       "   ('emūqu[strength]n', 0.021597682190713355),\n",
       "   ('qerēbu[approach]v', 0.019947428696239278),\n",
       "   ('ahu[arm]n', 0.019740957644432563)]),\n",
       " (2,\n",
       "  [('imēru[unit]n', 0.030122443604260522),\n",
       "   ('zēru[seed(s)]n', 0.025194620302352387),\n",
       "   ('kurummatu[ration]n', 0.024841798524694064),\n",
       "   ('aṣû[go-out]v', 0.021000240270188524),\n",
       "   ('ṣābu[people]n', 0.019797700103309897),\n",
       "   ('karāru[put-(down)]v', 0.018787295306361553),\n",
       "   ('ālu[city]n', 0.016822973625162357),\n",
       "   ('akālu[eat]v', 0.015189208465680504),\n",
       "   ('rabû[big-one]n', 0.014239409803581621),\n",
       "   ('ašābu[sit-(down)]v', 0.013106799375554)]),\n",
       " (3,\n",
       "  [('ṣābu[people]n', 0.060506319140804954),\n",
       "   ('ṣabātu[seize]v', 0.053962803287337144),\n",
       "   ('aṣû[go-out]v', 0.02909775978235787),\n",
       "   ('ammatu[unit]n', 0.025116514468196363),\n",
       "   ('dullu[trouble]n', 0.02275981870897022),\n",
       "   ('ṭēmu[(fore)thought]n', 0.020465223753710557),\n",
       "   ('sinništu[woman]n', 0.02007664918687474),\n",
       "   ('abu[father]n', 0.01764471958032646),\n",
       "   ('târu[turn]v', 0.014935665737406381),\n",
       "   ('hubtu[robbery]n', 0.014927357404630911)]),\n",
       " (4,\n",
       "  [('ṣarpu[silver]n', 0.03122888998681286),\n",
       "   ('ṣābu[people]n', 0.024920976292000758),\n",
       "   ('ālu[city]n', 0.024703208708128192),\n",
       "   ('manû[unit]n', 0.024399087417712951),\n",
       "   ('mahāru[face]v', 0.022220413444013026),\n",
       "   ('kurummatu[ration]n', 0.021433704894061625),\n",
       "   ('ēkallu[palace]n', 0.020297776531101298),\n",
       "   ('šipru[sending]n', 0.017195987391848876),\n",
       "   ('maddattu[payment]n', 0.017133291153480643),\n",
       "   ('dullu[trouble]n', 0.016558094462282947)]),\n",
       " (5,\n",
       "  [('ahu[brother]n', 0.082553153876217686),\n",
       "   ('ṭūbu[goodness]n', 0.048034691354991957),\n",
       "   ('abu[father]n', 0.039633889964737913),\n",
       "   ('ṭuppu[tablet]n', 0.039154879898070948),\n",
       "   ('ilu[god]n', 0.030772689880974643),\n",
       "   ('šīru[flesh]n', 0.028705421463788107),\n",
       "   ('karābu[pray]v', 0.026887845638217944),\n",
       "   ('mātu[land]n', 0.022031969576406071),\n",
       "   ('qātu[hand]n', 0.019071951356628026),\n",
       "   ('qaqqaru[ground]n', 0.01822456006477037)]),\n",
       " (6,\n",
       "  [('mātu[land]n', 0.079461990045652631),\n",
       "   ('maṣṣartu[observation]n', 0.042722342276050332),\n",
       "   ('ṣābu[people]n', 0.027467328011182852),\n",
       "   ('ṭēmu[(fore)thought]n', 0.020519125711335087),\n",
       "   ('birtu[fort]n', 0.017671498024153617),\n",
       "   ('naṣāru[guard]v', 0.017559589878049207),\n",
       "   ('šipru[sending]n', 0.017102686384293863),\n",
       "   ('nišu[people]n', 0.016975403830498802),\n",
       "   ('wadû[know]v', 0.015765552451278812),\n",
       "   ('ṣabātu[seize]v', 0.01565467508102018)]),\n",
       " (7,\n",
       "  [('ālu[city]n', 0.048470392408433177),\n",
       "   ('šipru[sending]n', 0.040234123467029752),\n",
       "   ('ṭēmu[(fore)thought]n', 0.036966811813686905),\n",
       "   ('pīhātu[responsibility]n', 0.030634580682053898),\n",
       "   ('ṣābu[people]n', 0.025208559656656408),\n",
       "   ('eqlu[field]n', 0.025186384102612102),\n",
       "   ('ēkallu[palace]n', 0.023861294802483439),\n",
       "   ('sahāru[go-around]v', 0.021580418406986657),\n",
       "   ('rabû[big-one]n', 0.021217771242677787),\n",
       "   ('ša-rēši[eunuch]n', 0.018525355365455)]),\n",
       " (8,\n",
       "  [('karābu[pray]v', 0.066363312908185063),\n",
       "   ('ilu[god]n', 0.040077548413338791),\n",
       "   ('akalu[bread]n', 0.029264270495285259),\n",
       "   ('balāṭu[live]v', 0.026066012233214322),\n",
       "   ('wadû[know]v', 0.022992953299351689),\n",
       "   ('napištu[throat]n', 0.022144569488550331),\n",
       "   ('ummu[mother]n', 0.021831924183224664),\n",
       "   ('mārtu[daughter]n', 0.018421010014271069),\n",
       "   ('šarrūtu[kingship]n', 0.015422110154167109),\n",
       "   ('akālu[eat]v', 0.015231564832222873)]),\n",
       " (9,\n",
       "  [('ilu[god]n', 0.044078106258822115),\n",
       "   ('dullu[trouble]n', 0.03988118243713476),\n",
       "   ('karābu[pray]v', 0.025969839207014424),\n",
       "   ('rēšu[head]n', 0.019547366148551116),\n",
       "   ('dīnu[legal-decision]n', 0.017269230207360351),\n",
       "   ('qātu[hand]n', 0.013921786710868566),\n",
       "   ('mātu[land]n', 0.013722980136155295),\n",
       "   ('antalû[eclipse]n', 0.01341151801338966),\n",
       "   ('abāku[lead-away]v', 0.013385440366418231),\n",
       "   ('libittu[mudbrick]n', 0.012791871240850903)])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.show_topics(ntopics, formatted = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyLDAvis\n",
    "Use pyLDAvis to visualize the topic model. By default, pyLDAvis will order the topics by [prevalence](https://github.com/bmabey/pyLDAvis/issues/59) (topic 1 is the most prevalent topic). That means that the topic numbers in the visualization do not agree with the topic numbers in the lda model. To prevent this behaviour one may use `sort_topics=False` in the `prepare` command. The advantage of ordering the topics by prevalence, however, is that new instances of the lda model are more comparable (that is, the same topic will receive the same number). Note that the library was written in Java for R, and so the numbering in the visualization begins with 1 (not with 0). The topic numbers in the Document/Topic and Topic/Term matrices below will be adjusted to be compatible with the pyLDAvis visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "    import pyLDAvis.gensim\n",
    "vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.save_html(vis, 'saao.html')\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Document/Topic Table\n",
    "Create a DataFrame that gives the probability of each topic for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_of_doctopics = [ldamodel.get_document_topics(corpus[i], minimum_probability=0) for i in range(len(corpus))]\n",
    "list_of_probabilities = [[probability for label,probability in distribution] for distribution in list_of_doctopics]\n",
    "df_list = [pd.DataFrame(list_of_probabilities[i]).transpose() for i in range(len(corpus))]\n",
    "doc_topic_df = pd.concat(df_list)\n",
    "doc_topic_df = doc_topic_df.set_index(saao_data_df.index)\n",
    "doc_topic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename the topics `topic 1` to `topic n` in accordance with the pyLDAvis visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = ['topic ' + str(i+1) for i in range(ntopics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "doc_topic_df.columns = topics\n",
    "doc_topic_df['text_name'] = saao_data_df['text_name']\n",
    "doc_topic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create Topic / Term table\n",
    "This is a table with N rows (the number of topics) and M columns (the number of individual terms in the Dictionary). The table indicates the probability of each term in each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_term = ldamodel.show_topics(ntopics, formatted=False, num_words=len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object `topic_term` is a list of list. Each topic is represented by a list of tuples in the form `(word, probability)`. The following code pulls out the probabilities for each word in each topic (`topic_term[i][1]`) and creates a list of DataFrames with the words as index (rows) and the probabilities as the only column. Each Dataframe is transposed and the DataFrames are concatenated to a single DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_term_list = [pd.DataFrame(topic_term[i][1]).set_index(0).transpose() for i in range(0, ntopics)]\n",
    "topic_term_df = pd.concat(topic_term_list, ignore_index=True)\n",
    "topic_term_df['topics'] = topics\n",
    "topic_term_df = topic_term_df.set_index('topics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topics (rows) are numbered 0-14 in the (random) order of the lda model. The array `prevalences` is used to re-arrange the topics in the order of prevalence (as is done above for the document/topic matrix). The re-arranged topics (rows) are now re-labeled `topic 1` to `topic 15` in accordance with their numbering in the pyLDAvis visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#topic_term_df['ēkallu[palace]n']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Documents 1.: Using MDS\n",
    "\n",
    "While pyLDAvis is an excellent tool for exploring the topic/term aspect of a topic model (the words and their probabilities in each topic) it does not provide access to the document/topic aspect (the probability distribution of topics in each document). The visualization below plots all the documents according to their distances (using Multi-Dimensional Scaling) in the Document/Topic DataFrame. Each document (dot) is colored according to the most prevalent topic and the size of the dot represents the probability of the most prevalent topic in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the distances between each of the documents. Use either the Document/Topic Dataframe or the Document/Term Dataframe (constructed below) to measure distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer='word', token_pattern=r'[^ ]+', vocabulary=list(topic_term_df.columns.values))\n",
    "saao_dtm = cv.fit_transform(saao_data_df['text'])\n",
    "saao_dtm_df = pd.DataFrame(saao_dtm.toarray(), columns = cv.get_feature_names(), index = saao_data_df.index.values)\n",
    "saao_dtm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dist = squareform(pdist(saao_dtm_df))\n",
    "dist = squareform(pdist(doc_topic_df.drop('text_name', axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the position of each document using Multi-Dimensional Scaling. The variable `pos` holds the `x` and `y`  coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mds = MDS(n_components=2, max_iter=3000,\n",
    "      random_state=seed, dissimilarity=\"precomputed\", n_jobs=1)\n",
    "\n",
    "pos = mds.fit(dist).embedding_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of x values (coordinates) and a list of y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_x = [x for x, y in pos]\n",
    "pos_y = [y for x, y in pos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create lists of the most prevalent topic, the probability of the most prevalent topic, and the text name for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prevalent_topic = doc_topic_df.drop('text_name', axis=1).idxmax(axis=1)\n",
    "probability = [doc_topic_df.ix[i][prevalent_topic[i]] for i in range(0, len(corpus))]\n",
    "text_name = [name for name in doc_topic_df['text_name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import bokeh and draw the visualization. The visualization provides various tools for further exploration:\n",
    "- tooltips (provides topic, probability, text name and URL)\n",
    "- box zoom\n",
    "- wheel zoom\n",
    "- pan\n",
    "- reset\n",
    "- link to document edition\n",
    "- save the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, OpenURL, TapTool, HoverTool\n",
    "from bokeh.plotting import figure, output_file, output_notebook, show\n",
    "from collections import OrderedDict\n",
    "output_notebook()\n",
    "\n",
    "p = figure(\n",
    "    plot_width=800, plot_height=800,\n",
    "    tools=\"tap,pan,wheel_zoom,box_zoom,reset,save\", \n",
    "    title=\"Topic Distribution MDS.\\nSize of the circle represents prevalence of the topic\")\n",
    "p.add_tools(HoverTool(\n",
    "        tooltips=[\n",
    "            (\"url\", \"http://oracc.org/\" + \"@id_text\"),\n",
    "            ((\"topic, probability\"), (\"@topic, @probability\")),\n",
    "            (\"text name\", \"@text_name\")\n",
    "        ]\n",
    "        ))\n",
    "\n",
    "colormap = [('topic 1', \"orange\"), ('topic 2', \"olive\"), ('topic 3', \"firebrick\"), \n",
    "          ('topic 4', \"gold\"), ('topic 5', \"red\"), ('topic 6', \"black\"), ('topic 7', \"green\"), \n",
    "          ('topic 8', \"blue\"), ('topic 9', \"purple\"), ('topic 10', \"darkslategray\"), ('topic 11', \"yellow\"), \n",
    "          ('topic 12', \"indigo\"), ('topic 13', \"blueviolet\"), ('topic 14', \"saddlebrown\"), ('topic 15',\"navy\"), ('topic 16', 'orange'),\n",
    "           ('topic 17', 'olive'), ('topic 18', 'firebrick'), ('topic 19', 'gold'), ('topic 20', 'red'), ('topic 21', 'black'),\n",
    "            ('topic 22', 'green'), ('topic 23', 'blue'), ('topic 24', 'purple'), ('topic 25', 'darkslategray')]\n",
    "colormap = OrderedDict(colormap)\n",
    "colors = [colormap[n] for n in prevalent_topic]\n",
    "color_list = [colormap[topic] for topic in colormap]\n",
    "color_list += [\"black\"] * (len(colors) - len(color_list))\n",
    "source = ColumnDataSource(data=dict(\n",
    "        x=pos_x,\n",
    "        y=pos_y,\n",
    "        id_text=list(doc_topic_df.index.values),\n",
    "        size = probability/max(probability)*25,\n",
    "        probability = probability,\n",
    "        topic = prevalent_topic,\n",
    "        color = colors,\n",
    "        orig_color = color_list,\n",
    "        text_name = text_name\n",
    "    ))\n",
    "\n",
    "p.circle('x', 'y', color='color', fill_alpha=0.5, size='size', source=source)\n",
    "\n",
    "url = \"http://oracc.museum.upenn.edu/@id_text\"\n",
    "    \n",
    "\n",
    "taptool = p.select(type=TapTool)\n",
    "taptool.callback = OpenURL(url=url)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following graph is essentially the same but uses two sliders to choose two topic. The idea is to color the dots (documents) that have high prevalence for those topics and leave the other dots gray. This version is particuarly useful when modeling with many topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import vform\n",
    "from bokeh.models import ColumnDataSource, OpenURL, TapTool, HoverTool, CustomJS\n",
    "from bokeh.models.widgets import Slider\n",
    "from bokeh.plotting import figure, output_file, output_notebook, show\n",
    "from bokeh.layouts import widgetbox, column\n",
    "from collections import OrderedDict\n",
    "output_notebook()\n",
    "\n",
    "p = figure(\n",
    "    plot_width=800, plot_height=800,\n",
    "    tools=\"tap,pan,wheel_zoom,box_zoom,reset,save\", \n",
    "    title=\"Topic Distribution MDS\\nSize of the circle represents prevalence of the topic\")\n",
    "p.add_tools(HoverTool(\n",
    "        tooltips=[\n",
    "            (\"url\", \"http://oracc.org/\" + \"@id_text\"),\n",
    "            ((\"topic, probability\"), (\"@topic, @probability\")),\n",
    "            (\"text name\", \"@text_name\")\n",
    "        ]\n",
    "        ))\n",
    "\n",
    "\n",
    "colormap = [('topic 1', \"orange\"), ('topic 2', \"olive\"), ('topic 3', \"firebrick\"), \n",
    "          ('topic 4', \"gold\"), ('topic 5', \"red\"), ('topic 6', \"black\"), ('topic 7', \"green\"), \n",
    "          ('topic 8', \"blue\"), ('topic 9', \"purple\"), ('topic 10', \"darkslategray\"), ('topic 11', \"yellow\"), \n",
    "          ('topic 12', \"indigo\"), ('topic 13', \"blueviolet\"), ('topic 14', \"saddlebrown\"), ('topic 15',\"navy\"), ('topic 16', 'orange'),\n",
    "           ('topic 17', 'olive'), ('topic 18', 'firebrick'), ('topic 19', 'gold'), ('topic 20', 'red'), ('topic 21', 'black'),\n",
    "            ('topic 22', 'green'), ('topic 23', 'blue'), ('topic 24', 'purple'), ('topic 25', 'darkslategray')]\n",
    "colormap = OrderedDict(colormap)\n",
    "colors = [colormap[n] for n in prevalent_topic]\n",
    "color_list = [colormap[topic] for topic in colormap]\n",
    "color_list += [\"black\"] * (len(colors) - len(color_list))\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "        x=pos_x,\n",
    "        y=pos_y,\n",
    "        id_text=list(doc_topic_df.index.values),\n",
    "        size = probability/max(probability)*25,\n",
    "        probability = probability,\n",
    "        topic = prevalent_topic,\n",
    "        color = colors,\n",
    "        orig_color = color_list,\n",
    "        text_name = text_name\n",
    "    ))\n",
    "\n",
    "p.circle('x', 'y', color='color', fill_alpha=0.5, size='size', source=source)\n",
    "\n",
    "callback = CustomJS(args=dict(source=source), code = \"\"\"\n",
    "    var data = source.get('data');\n",
    "    var current_topic_1 = topic1.value;\n",
    "    var current_topic_2 = topic2.value;\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    col = data['color']\n",
    "    topic = data['topic']\n",
    "\n",
    "    orig_color = data['orig_color']\n",
    "    for (i = 0; i < x.length; i++) {\n",
    "        if (topic[i].substring(6) == current_topic_1) {\n",
    "            col[i] = orig_color[current_topic_1 - 1]\n",
    "        } else {\n",
    "            col[i] = 'grey'\n",
    "        }\n",
    "        if (topic[i].substring(6) == current_topic_2) {\n",
    "            col[i] = orig_color[current_topic_2 - 1]\n",
    "        }\n",
    "    }\n",
    "    source.trigger('change');\n",
    "\"\"\")\n",
    "\n",
    "topic_slider = Slider(start=1, end = ntopics, value=1, step=1, title = 'Topic', callback=callback)\n",
    "callback.args['topic1'] = topic_slider\n",
    "topic_slider2 = Slider(start=1, end = ntopics, value=1, step=1, title = 'Topic', callback=callback)\n",
    "callback.args['topic2'] = topic_slider2\n",
    "\n",
    "url = \"http://oracc.museum.upenn.edu/@id_text\"\n",
    "\n",
    "taptool = p.select(type=TapTool)\n",
    "taptool.callback = OpenURL(url=url)\n",
    "\n",
    "show(column(topic_slider, topic_slider2, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization 2\n",
    "\n",
    "The visualization below does essentially the same thing: each document (dot) is colored according to the most prevalent topic and the size of the dot represents the probability of the most prevalent topic in that document. The position of the dot (embedding), in this case, is computed with t-SNE ([t-distributed Stochastic Neighbor Embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)).\n",
    "The coding in Bokeh is essentially the same and thus provides the same tools: links to the documents, tooltips, zooming, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = doc_topic_df.drop('text_name', axis=1).as_matrix()\n",
    "tsne = TSNE(n_components = 2, init = 'pca', random_state=0)\n",
    "X_tsne = tsne.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne_x = [x for x, y in X_tsne]\n",
    "tsne_y = [y for x, y in X_tsne]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.io import vform\n",
    "from bokeh.models import ColumnDataSource, OpenURL, TapTool, HoverTool, CustomJS\n",
    "from bokeh.models.widgets import Slider\n",
    "from bokeh.plotting import figure, output_file, output_notebook, show\n",
    "from bokeh.layouts import widgetbox, column\n",
    "from collections import OrderedDict\n",
    "output_notebook()\n",
    "\n",
    "p = figure(\n",
    "    plot_width=800, plot_height=800,\n",
    "    tools=\"tap,pan,wheel_zoom,box_zoom,reset,save\", \n",
    "    title=\"Topic Distribution tSNE.\\nSize of the circle represents prevalence of the topic\")\n",
    "p.add_tools(HoverTool(\n",
    "        tooltips=[\n",
    "            (\"url\", \"http://oracc.org/\" + \"@id_text\"),\n",
    "            ((\"topic, probability\"), (\"@topic, @probability\")),\n",
    "            (\"text name\", \"@text_name\")\n",
    "        ]\n",
    "        ))\n",
    "\n",
    "\n",
    "colormap = [('topic 1', \"orange\"), ('topic 2', \"olive\"), ('topic 3', \"firebrick\"), \n",
    "          ('topic 4', \"gold\"), ('topic 5', \"red\"), ('topic 6', \"black\"), ('topic 7', \"green\"), \n",
    "          ('topic 8', \"blue\"), ('topic 9', \"purple\"), ('topic 10', \"darkslategray\"), ('topic 11', \"yellow\"), \n",
    "          ('topic 12', \"indigo\"), ('topic 13', \"blueviolet\"), ('topic 14', \"saddlebrown\"), ('topic 15',\"navy\"), ('topic 16', 'orange'),\n",
    "           ('topic 17', 'olive'), ('topic 18', 'firebrick'), ('topic 19', 'gold'), ('topic 20', 'red'), ('topic 21', 'black'),\n",
    "            ('topic 22', 'green'), ('topic 23', 'blue'), ('topic 24', 'purple'), ('topic 25', 'darkslategray')]\n",
    "colormap = OrderedDict(colormap)\n",
    "colors = [colormap[n] for n in prevalent_topic]\n",
    "color_list = [colormap[topic] for topic in colormap]\n",
    "color_list += [\"black\"] * (len(colors) - len(color_list))\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "        x=tsne_x,\n",
    "        y=tsne_y,\n",
    "        id_text=list(doc_topic_df.index.values),\n",
    "        size = probability/max(probability)*25,\n",
    "        probability = probability,\n",
    "        topic = prevalent_topic,\n",
    "        color = colors,\n",
    "        orig_color = color_list,\n",
    "        text_name = text_name\n",
    "    ))\n",
    "\n",
    "p.circle('x', 'y', color='color', fill_alpha=0.5, size='size', source=source)\n",
    "\n",
    "callback = CustomJS(args=dict(source=source), code = \"\"\"\n",
    "    var data = source.get('data');\n",
    "    var current_topic_1 = topic1.value;\n",
    "    var current_topic_2 = topic2.value;\n",
    "    x = data['x']\n",
    "    y = data['y']\n",
    "    col = data['color']\n",
    "    topic = data['topic']\n",
    "\n",
    "    orig_color = data['orig_color']\n",
    "    for (i = 0; i < x.length; i++) {\n",
    "        if (topic[i].substring(6) == current_topic_1) {\n",
    "            col[i] = orig_color[current_topic_1 - 1]\n",
    "        } else {\n",
    "            col[i] = 'grey'\n",
    "        }\n",
    "        if (topic[i].substring(6) == current_topic_2) {\n",
    "            col[i] = orig_color[current_topic_2 - 1]\n",
    "        }\n",
    "    }\n",
    "    source.trigger('change');\n",
    "\"\"\")\n",
    "\n",
    "topic_slider = Slider(start=1, end = ntopics, value=1, step=1, title = 'Topic', callback=callback)\n",
    "callback.args['topic1'] = topic_slider\n",
    "topic_slider2 = Slider(start=1, end = ntopics, value=1, step=1, title = 'Topic', callback=callback)\n",
    "callback.args['topic2'] = topic_slider2\n",
    "\n",
    "url = \"http://oracc.museum.upenn.edu/@id_text\"\n",
    "\n",
    "taptool = p.select(type=TapTool)\n",
    "taptool.callback = OpenURL(url=url)\n",
    "\n",
    "show(column(topic_slider, topic_slider2, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
